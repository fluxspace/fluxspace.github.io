<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description"
        content="FluxSpace is a text-guided image editing fraemwork for rectified flow transformers.">
        <meta name="keywords" content="Diffusion Models, Latent Space Exploration">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <script src="https://www.w3counter.com/tracker.js?id=154617"></script>
        <title>FluxSpace</title>
        <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
        dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
        </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    </head>

    <body>
        <section class="hero is-light">
            <div class="hero-body">
              <div class="container is-max-desktop">
                <div class="columns is-centered">
                  <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">FluxSpace: Disentangled Image Editing in Rectified Flow Models</h1>
                    <div class="is-size-5 publication-authors">
                      <span class="author-block">
                        <a href="https://yusufdalva.github.io/">Yusuf Dalva</a>,</span>
                        <span class="author-block">
                            <a href="https://sanghani.cs.vt.edu/person/kavana-venkatesh/">Kavana Venkatesh</a>,</span>
                      <span class="author-block">
                        <a href="https://pinguar.org/">Pinar Yanardag</a>
                      </span>
                    </div>
          
                    <div class="is-size-5 publication-authors">
                      <span class="author-block">Virginia Tech</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
      
                          <span class="link-block">
                            <a href="https://arxiv.org/abs/2312.05390"
                               class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                  <i class="fas fa-file-pdf"></i>
                              </span>
                              <span>Paper</span>
                            </a>
                          </span>
      
                          <span class="link-block">
                            <a href=""
                               class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                  <i class="fab fa-github"></i>
                              </span>
                              <span>Code (coming soon)</span>
                              </a>
                          </span>
                        </div>
                    </div>
                </div>
              </div>
            </div>
          </div>
        </section>

        <section class="hero teaser">
            <div class="container is-max-desktop">
              <div class="hero-body">
                <h4 class="subtitle">
                    <br>
                    <b>TL;DR</b> We propose a text-guided dual-level image editing framework for rectified flow transformers, enabling fine-grained and coarse editing by 
                    leveraging semantically interpretable attention outputs.
                    <!--
                    <span class="dnerf">NoiseCLR</span> discovers semantic directions in latent diffusion models in a completely unsupervised manner. 
                    With this work, we present latent directions discovered in domains such as Art, Fashion, Face, Cats and Cars in Stable Diffusion. -->
                </h4>
                <div class="container">
                    <img src="./static/images/teaser.png" />
                    <br/>
                    <p>
                      We propose a text-guided image editing approach on rectified flow transformers, such as Flux. Our method can generalize to semantic edits on different 
                      domains such as humans, animals, cars, and extends to even more complex scenes such as an image of a street (third row, first example). FluxSpace can apply edits described as 
                      keywords (e.g. "truck" for transforming a car into a truck) and offers disentangled editing capabilities that do not require manually provided masks to target a specific aspect 
                      in the original image. In addition, our method does not require any training and can apply the desired edit during inference time.
                    </p>
                </div>
            </div>
        </section>

        <section class="section hero is-light">
            <div class="container is-max-desktop">
              <!-- Abstract. -->
              <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                  <h2 class="title is-3">Abstract</h2>
                  <div class="content has-text-justified">
                    <p>
                      Rectified flow models have emerged as a dominant approach in image generation, showcasing impressive capabilities in high-quality image synthesis. However, despite their effectiveness 
                      in visual generation, rectified flow models often struggle with disentangled editing of images. This limitation prevents the ability to perform precise, attribute-specific modifications 
                      without affecting unrelated aspects of the image. In this paper, we introduce FluxSpace, a domain-agnostic image editing method leveraging a representation space with the ability to control 
                      the semantics of images generated by rectified flow transformers, such as Flux. By leveraging the representations learned by the transformer blocks within the rectified flow models, we propose 
                      a set of semantically interpretable representations that enable a wide range of image editing tasks, from fine-grained image editing to artistic creation. This work offers a scalable and effective 
                      image editing approach, along with its disentanglement capabilities.
                    </p>
                  </div>
                </div>
              </div>
        </section>

        <section class="section">
            <div class="container is-max-desktop">
              <div class="columns is-centered has-text-centered">
                <div class="column is-12">
                  <h2 class="title is-3">Method</h2>
        
                  <div class="content has-text-justified">
                    <!--
                    <p>
                     Explain method
                    </p>
                  -->
                    <div class="container">
                      <img src="./static/images/framework_v2.png" />
                      <br />
                    </div>
        
                    <p>
                        The FluxSpace framework introduces a dual-level editing scheme within the joint transformer blocks of Flux, enabling coarse and fine-grained visual editing. Coarse editing operates on pooled representations 
                        of base (<b>c<sub>pool</sub></b>) and edit (<b>c<sub>e, pool</sub></b>) conditions, allowing global changes like stylization, controlled by the scale <b>&lambda;<sub>coarse</sub></b> (a). For fine-grained editing, we define a linear editing scheme using 
                        base, prior and edit attention outputs, guided by scale <b>&lambda;<sub>context</sub></b> (b). With this dual level design, our framework is both able to perform coarse-level and fine-grained editing, with a linearly adjustable scale. 
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </section>
              
        
          <section class="section">
            <div class="container is-max-desktop">
                <h1 class="title is-3 has-text-centered">Editing Results</h1>
              <div class="columns is-centered has-text-centered">
                <div class="column is-12">
        
                  <div class="content has-text-justified">
                    <!--
                    <p>
                     Explain method
                    </p>
                  -->
                  <h4 class="title is-4 has-text-centered">Face Editing with Different Concepts</h4>
                    <div class="container">
                      <img src="./static/images/edits_face.png" />
                      <br />
                    </div>
                    <p>
                        Our method is able to perform a variety edits from fine grained face editing (e.g. adding eyeglasses) to changes over the overall structure of the image (e.g. comics style).
                    </p>

                    <h4 class="title is-4 has-text-centered">Editing with Multiple Subjects</h4>
                    <div class="container">
                      <img src="./static/images/supp_multi_subject.png" />
                      <br />
                    </div>
        
                    <p>
                        In addition to images with only one subject to be edited, <i>FluxSpace</i> can apply edits by identifying semantics globally and editing multiple subjects at the same time.
                    </p>

                    <h4 class="title is-4 has-text-centered">Editing with Different Imaging Settings - Local Edits</h4>
        
                  <div class="content has-text-justified">
                    <!--
                    <p>
                     Explain method
                    </p>
                  -->
                    <div class="container">
                      <img src="./static/images/supp_sunglasses.png" />
                      <br />
                    </div>
                    <br>
                    <p>
                        <i>FluxSpace</i> is able to perform edits that result in local changes, such as adding sunglasses. Since we leverage the semantic understanding capabilities of Flux, 
                        we can precisely perform the desired edit on different imaging settings.
                    </p>
                    
                    <h4 class="title is-4 has-text-centered">Editing with Different Imaging Settings - Global Edits</h4>

                    <div class="container">
                        <img src="./static/images/supp_gender.png" />
                        <br />
                      </div>
                      <br>
                      <p>
                          <i>FluxSpace</i> can peform edits that result in changes in global appearance. In edits such as gender, where the overall subject is bound to significant changes, 
                          our framwork can preserve edit-irrelavent details and adjust the target subject sufficiently.
                      </p>
                  </div>
                </div>
              </div>
            </div>
          </section>

          <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
              <h2 class="title">BibTeX</h2>
              <pre><code>
  @misc{dalva2024fluxspace,
    title={FluxSpace: Disentangled Image Editing in Rectified Flow Models}, 
    author={Yusuf Dalva and Kavana Venkatesh and Pinar Yanardag},
    year={2024},
    eprint={TBD},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
  }
              </code></pre>
            </div>
          </section>

          <footer class="footer">
            <div class="container">
              <div class="content has-text-centered is-centered">
                <a class="icon-link" href="https://github.com/yusufdalva" class="external-link" disabled>
                  <i class="fab fa-github"></i>
                </a>
              </div>
              <div class="columns">
                <div class="column is-8">
                  <div class="content has-text-justified">
                    <!-- <p>
                      This website is licensed under a <a rel="license"
                                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                      Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p> -->
                    <p>This page is adapted from <a
                        href="https://github.com/nerfies/nerfies.github.io">this</a> implementation.
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </footer>
    </body>
</html>